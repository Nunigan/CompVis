{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Segmentation\n",
    "\n",
    "In this exercise we will look at different segmentation algorithms.\n",
    "\n",
    "##  Clustering\n",
    "\n",
    "One of the basic unsupervised learning approaches is clustering, where the algorithm has to find out which part of the data belongs together in one cluster. \n",
    "\n",
    "For segmentation, this data is taken from the pixel values, possible from a neighborhood of the pixels and often by calculating specific features in this region. However, for the moment we will use the raw (color) data of the pixels and possibly also the location and look at features later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.data\n",
    "import skimage.io\n",
    "import skimage.future\n",
    "import skimage.segmentation\n",
    "import sklearn.cluster\n",
    "import cv2\n",
    "\n",
    "# for displaying images in jupyter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "#mpl.rcParams['figure.dpi']= 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Exercise 1: Using KMeans for background subtraction on a medical image\n",
    "\n",
    "In the first exercise, we want to extract the background from an image showning the hands on green background. The image is a sample from out project to detect eczema, however we will only be concerned about finding the background and the hands.\n",
    "\n",
    "<img src=images/hand_green_small.png width=400px>\n",
    "\n",
    "This could also be achieved by defining a suitable range of color for either the background or the foreground and use thresholding. We want to find out, if it is also possible using k-Means.\n",
    "\n",
    "Use kmeans for clustering all the pixels in the image into 2 clusters using only the RGB values.\n",
    "\n",
    "If we use the raw pixels, the position of the pixels do not matter. You will have to reshape the image into a 1D Array of RGB values and convert them to float.\n",
    "\n",
    "There are different implementations of kmeans available, most noteworthy an opencv and a sklearn implementation. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = skimage.io.imread('images/hand_green_small.png')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means to find 2 clusters and display them\n",
    "# For displaying you can use either the found cluster centers as colors or overlay the labels, see skimage.color.label2rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "data = image.reshape((-1,3)).astype(np.float32)\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(data)\n",
    "center_colors = np.uint8(kmeans.cluster_centers_)\n",
    "labels_image = kmeans.labels_.reshape((image.shape[0], image.shape[1]))\n",
    "result = center_colors[labels_image]\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further questions\n",
    "\n",
    "How can you find out, if the segmentation was good or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a value that indicates the result of the k-means algorithm.\n",
    "print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: K-Means with multiple labels.\n",
    "\n",
    "Try the K-Means Algorithmus on the following image to seperate the different colored figures and the gray and black background.\n",
    "\n",
    "<img src=images/carcassonne_figures.jpg width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread('images/carcassonne_figures.jpg')\n",
    "data = image.reshape((-1,3)).astype(np.float32)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=8)\n",
    "kmeans.fit(data)\n",
    "center_colors = np.uint8(kmeans.cluster_centers_)\n",
    "labels_image = kmeans.labels_.reshape((image.shape[0], image.shape[1]))\n",
    "result = center_colors[labels_image]\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(result)\n",
    "plt.subplot(1, 2, 2)\n",
    "out = skimage.color.label2rgb(labels_image, image, kind='avg')\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further questions\n",
    "\n",
    "Try different values for the number of clusters. What results do you get?\n",
    "\n",
    "One for the problems is that similar colors with different intensity will end up in different clusters. How could you solve that issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different color space for k-Means\n",
    "image_lab = skimage.color.rgb2lab(image)\n",
    "plt.rcParams['figure.figsize'] = [12, 20]\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(image_lab[:,:,0], cmap='gray')\n",
    "print(np.max(image_lab[:,:,0]))\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(image_lab[:,:,1], cmap='gray')\n",
    "print(np.max(image_lab[:,:,1]))\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(image_lab[:,:,2], cmap='gray')\n",
    "print(np.max(image_lab[:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data for kmeans and display it as a scatter plot first\n",
    "data_2d = image_lab[:,:,1:3]\n",
    "data = data_2d.reshape((-1,2))\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "plt.plot(data[:,0], data[:,1], '.')\n",
    "np.max(data[:,0])\n",
    "np.max(data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sklearn.cluster.KMeans(n_clusters=5)\n",
    "kmeans.fit(data)\n",
    "kmeans.cluster_centers_\n",
    "labels_image = kmeans.labels_.reshape((image.shape[0], image.shape[1]))\n",
    "plt.imshow(skimage.color.label2rgb(labels_image, image, kind='avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=data[:,0], y=data[:,1], c=kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Different segmentations for autonoumous vehicels.  \n",
    "\n",
    "We want to try out different segmentation algorithms on a more difficult image from a dataset for semantic segmentation for autonomous vehicles:\n",
    "\n",
    "<img src=images/000041_10.png width=400px>\n",
    "\n",
    "### Exercise 3.1. k-Means\n",
    "\n",
    "Try K-Means on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread('images/000041_10.png')\n",
    "data = image.reshape((-1,3)).astype(np.float32)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=5)\n",
    "kmeans.fit(data)\n",
    "center_colors = np.uint8(kmeans.cluster_centers_)\n",
    "labels_image = kmeans.labels_.reshape((image.shape[0], image.shape[1]))\n",
    "result = center_colors[labels_image]\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Superpixel segmentation\n",
    "\n",
    "The skimage library has methods that directly segment the images into clusters using both the pixel coordinates and the color. Such methods are often used as a preliminary processing step of clustering an image into so called superpixel which can then be input into a further, often graph based, segmentation algorithm.\n",
    "\n",
    "Try this segmentation using \n",
    "http://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = skimage.segmentation.slic(image, n_segments=1000, compactness=10, multichannel=True)\n",
    "print(labels.shape)\n",
    "print(np.max(labels))\n",
    "plt.imshow(skimage.color.label2rgb(labels, image, kind='avg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: GraphCut\n",
    "\n",
    "The skimage packages contains a graph cut algorithms to segment a (superpixel) image using the graph cut algorithms.\n",
    "\n",
    "To use is, first the *Region Adjacency Graph* of the segmented superpixels must be constructed:\n",
    "\n",
    "http://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.rag_mean_color\n",
    "\n",
    "and then the graph cut algorithms can be applied:\n",
    "\n",
    "http://scikit-image.org/docs/dev/api/skimage.future.graph.html\n",
    "\n",
    "Use both methods to segment the result of the superpixel segmentation using graph cuts and display the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "graph = skimage.future.graph.rag_mean_color(image, labels, mode='similarity')\n",
    "labels2 = skimage.future.graph.cut_normalized(labels, graph, in_place=False)\n",
    "#print(labels)\n",
    "#print(labels2)\n",
    "plt.imshow(skimage.color.label2rgb(labels2, image, kind='avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.future.graph.show_rag(labels, graph, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Mean Shift Segmentation\n",
    "\n",
    "OpenCV contains a method to directly calculate a mean shift segmentation from an image:\n",
    "\n",
    "https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html\n",
    "\n",
    "Apply this method on the (original) image above and evaluate the result. Check the different parameter settings of the algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS, 1000, 0.001)\n",
    "mean_shift_image = cv2.pyrMeanShiftFiltering(image, sp=20.0, sr=50.0, maxLevel=1, termcrit=criteria)\n",
    "plt.imshow(mean_shift_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 (optional): k-Means with position and color\n",
    "\n",
    "Implement a k-Means clustering that uses the position of a pixel together with the color for clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread('images/carcassonne_figures.jpg')\n",
    "data_col = image.reshape((-1,3)).astype(np.float32) / 255.0\n",
    "idx = np.indices((image.shape[0], image.shape[1]))\n",
    "print(np.max(data_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.indices((image.shape[0], image.shape[1]))\n",
    "idx_all = np.stack([idx[0,:,:],idx[1,:,:]], axis=2)\n",
    "factor = 1.0\n",
    "data_idx = idx_all.reshape((-1,2)).astype(np.float32) * factor / np.max(idx_all)\n",
    "print(np.max(data_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_col.shape)\n",
    "print(data_idx.shape)\n",
    "data = np.concatenate([data_col, data_idx], axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sklearn.cluster.KMeans(n_clusters=11)\n",
    "kmeans.fit(data)\n",
    "kmeans.cluster_centers_\n",
    "labels_image = kmeans.labels_.reshape((image.shape[0], image.shape[1]))\n",
    "plt.imshow(skimage.color.label2rgb(labels_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
